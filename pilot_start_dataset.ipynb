{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.filter import filter_data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from scipy.signal import find_peaks_cwt, decimate\n",
    "from scipy.stats import spearmanr\n",
    "import time\n",
    "from entropy import shannon_entropy, sample_entropy\n",
    "\n",
    "from os import listdir\n",
    "    #method listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "from os.path import isfile, join\n",
    "    #returns true if file in path is an existing regular file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## !! set correct working directory\n",
    "#import os\n",
    "# path=\"/Volumes/Projects_div3/ADBS\"\n",
    "path = \"Y:/ADBS\"\n",
    "#os.chdir(path)\n",
    "#os.getcwd() #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\p3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Miniconda3\\envs\\p3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# prepare ESM export from server\n",
    "esm = df = pd.read_stata(path+'/esmDataPilot/PRDB_20181025T115653/SANPAR_BE.dta',convert_categoricals = False)\n",
    "esm = esm[['subjno', 'mood_well', 'mood_down', 'mood_fright', 'mood_tense', 'phy_sleepy', 'phy_tired',\n",
    "       'mood_cheerf', 'mood_relax', 'thou_concent', 'pat_hallu', 'loc_where',\n",
    "       'soc_who', 'soc_who02', 'soc_who03', 'act_what', 'act_what02',\n",
    "       'act_what03', 'act_norpob', 'sanpar_been', 'sanpar_stil',\n",
    "       'sanpar_spreken', 'sanpar_lopen', 'sanpar_tremor', 'sanpar_traag',\n",
    "       'sanpar_stijf', 'sanpar_spann', 'sanpar_beweeg', 'sanpar_onoff',\n",
    "       'sanpar_medic', 'beep_disturb', '_datetime', '_datetime_e', 'dayno_n', 'beepno_n']]\n",
    "esm['duration'] = esm['_datetime_e']-esm['_datetime']\n",
    "\n",
    "mapNames={}\n",
    "for i in range(20):\n",
    "    mapNames[9009989+i]=110001+i\n",
    "\n",
    "esm['castorID'] = [mapNames[e] for e in esm['subjno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of files per L/R/chest from directory (mypath)\n",
    "\n",
    "leftSensors = ['13797','13799','13794']\n",
    "rightSensors = ['13805','13801','13793']\n",
    "chestSensors = ['13804','13792','13803']\n",
    "\n",
    "featureWindowLength=60\n",
    "windowLength=60\n",
    "esmWindowLength=15\n",
    "\n",
    "mypath = 'C:/data/raw/MOX/110005/'\n",
    "bdffiles = [f for f in listdir(mypath) if isfile(join(mypath,f)) and f[0]!='_' and f[-3:] =='edf']\n",
    "#bdffiles are the files in mypath, not directories\n",
    "\n",
    "leftFiles = []\n",
    "rightFiles = []\n",
    "chestFiles = []\n",
    "\n",
    "for f in bdffiles:\n",
    "    if f[0:5] in leftSensors:\n",
    "        leftFiles.append(mypath + f)\n",
    "    elif f[0:5] in rightSensors:\n",
    "        rightFiles.append(mypath + f)\n",
    "    elif f[0:5] in chestSensors:\n",
    "        chestFiles.append(mypath + f)\n",
    "\n",
    "leftFiles=sorted(leftFiles)\n",
    "rightFiles=sorted(rightFiles)\n",
    "chestFiles=sorted(chestFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/data/raw/MOX/110005/13799_20181002_060804.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\p3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\ProgramData\\Miniconda3\\envs\\p3\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/data/raw/MOX/110005/13799_20181003_070253.edf\n",
      "C:/data/raw/MOX/110005/13799_20181003_070253.edf is broken\n",
      "C:/data/raw/MOX/110005/13799_20181003_070256.edf\n",
      "C:/data/raw/MOX/110005/13799_20181004_000000.edf\n",
      "C:/data/raw/MOX/110005/13799_20181004_083502.edf\n",
      "C:/data/raw/MOX/110005/13799_20181005_074601.edf\n",
      "C:/data/raw/MOX/110005/13799_20181006_000000.edf\n",
      "C:/data/raw/MOX/110005/13799_20181006_084256.edf\n",
      "C:/data/raw/MOX/110005/13799_20181007_082759.edf\n",
      "C:/data/raw/MOX/110005/13799_20181008_083214.edf\n",
      "C:/data/raw/MOX/110005/13799_20181009_081701.edf\n",
      "C:/data/raw/MOX/110005/13799_20181010_071928.edf\n",
      "C:/data/raw/MOX/110005/13799_20181011_000000.edf\n",
      "C:/data/raw/MOX/110005/13799_20181011_075902.edf\n",
      "C:/data/raw/MOX/110005/13799_20181012_080146.edf\n",
      "C:/data/raw/MOX/110005/13799_20181013_000000.edf\n",
      "C:/data/raw/MOX/110005/13799_20181013_084619.edf\n",
      "C:/data/raw/MOX/110005/13799_20181014_000000.edf\n",
      "C:/data/raw/MOX/110005/13799_20181014_082141.edf\n",
      "C:/data/raw/MOX/110005/13799_20181015_000000.edf\n",
      "C:/data/raw/MOX/110005/13799_20181015_082715.edf\n",
      "C:/data/raw/MOX/110005/13801_20181002_060809.edf\n",
      "C:/data/raw/MOX/110005/13801_20181003_070256.edf\n",
      "C:/data/raw/MOX/110005/13801_20181004_000000.edf\n",
      "C:/data/raw/MOX/110005/13801_20181004_083502.edf\n",
      "C:/data/raw/MOX/110005/13801_20181005_074600.edf\n",
      "C:/data/raw/MOX/110005/13801_20181006_000000.edf\n",
      "C:/data/raw/MOX/110005/13801_20181006_084254.edf\n",
      "C:/data/raw/MOX/110005/13801_20181007_082756.edf\n",
      "C:/data/raw/MOX/110005/13801_20181008_083213.edf\n",
      "C:/data/raw/MOX/110005/13801_20181009_081702.edf\n",
      "C:/data/raw/MOX/110005/13801_20181010_071929.edf\n",
      "C:/data/raw/MOX/110005/13801_20181011_000000.edf\n",
      "C:/data/raw/MOX/110005/13801_20181011_075901.edf\n",
      "C:/data/raw/MOX/110005/13801_20181012_080143.edf\n",
      "C:/data/raw/MOX/110005/13801_20181013_000000.edf\n",
      "C:/data/raw/MOX/110005/13801_20181013_084617.edf\n",
      "C:/data/raw/MOX/110005/13801_20181014_000000.edf\n",
      "C:/data/raw/MOX/110005/13801_20181014_082139.edf\n",
      "C:/data/raw/MOX/110005/13801_20181015_000000.edf\n",
      "C:/data/raw/MOX/110005/13801_20181015_082713.edf\n",
      "C:/data/raw/MOX/110005/13792_20181002_060800.edf\n",
      "C:/data/raw/MOX/110005/13792_20181003_070254.edf\n",
      "C:/data/raw/MOX/110005/13792_20181004_000000.edf\n",
      "C:/data/raw/MOX/110005/13792_20181004_083500.edf\n",
      "C:/data/raw/MOX/110005/13792_20181005_074557.edf\n",
      "C:/data/raw/MOX/110005/13792_20181006_000000.edf\n",
      "C:/data/raw/MOX/110005/13792_20181006_084251.edf\n",
      "C:/data/raw/MOX/110005/13792_20181007_082754.edf\n",
      "C:/data/raw/MOX/110005/13792_20181008_083207.edf\n",
      "C:/data/raw/MOX/110005/13792_20181009_081656.edf\n",
      "C:/data/raw/MOX/110005/13792_20181010_071922.edf\n",
      "C:/data/raw/MOX/110005/13792_20181011_000000.edf\n",
      "C:/data/raw/MOX/110005/13792_20181011_075853.edf\n",
      "C:/data/raw/MOX/110005/13792_20181012_080136.edf\n",
      "C:/data/raw/MOX/110005/13792_20181013_000000.edf\n",
      "C:/data/raw/MOX/110005/13792_20181013_084608.edf\n",
      "C:/data/raw/MOX/110005/13792_20181014_000000.edf\n",
      "C:/data/raw/MOX/110005/13792_20181014_082130.edf\n",
      "C:/data/raw/MOX/110005/13792_20181015_000000.edf\n",
      "C:/data/raw/MOX/110005/13792_20181015_082703.edf\n"
     ]
    }
   ],
   "source": [
    "testL,testR,testC = extractAllSensors(leftFiles,rightFiles,chestFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAllSensors(leftFiles,rightFiles,chestFiles,featureWindowLength=60):\n",
    "    # Read in the three list of files\n",
    "    #Process leftWristData\n",
    "    leftWristDF=[]\n",
    "    rightWristDF=[]\n",
    "    chestDF=[]\n",
    "    accelerometerChannel=[0,1,2] # assuming acc xyz 0-1-2 is\n",
    "    files = [leftFiles, rightFiles, chestFiles]\n",
    "    dfs = [leftWristDF,rightWristDF, chestDF]\n",
    "    identifiers = ['l', 'r', 'c']\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        for file in f:\n",
    "            print(file)\n",
    "            try:\n",
    "                labels, startTime, data, sr = readData(file) ## as input instead: leftFiles\n",
    "                data = decimate(data,2,axis=1)\n",
    "                sr = int(sr /2)\n",
    "                if data.shape[1]<sr * featureWindowLength:\n",
    "                    raise ValueError('File too short to proceed.')\n",
    "        #Could be left wrist specific or general\n",
    "            except:\n",
    "                print('%s is broken' % file)\n",
    "                continue\n",
    "\n",
    "    \n",
    "    \n",
    "            data[:,accelerometerChannel] = (data[:,accelerometerChannel].T - np.mean(data[:,accelerometerChannel].T,axis=0)).T\n",
    "            data[:,accelerometerChannel] = filter_data(data[:,accelerometerChannel],sr,0,3,method='iir',verbose='WARNING')\n",
    "            alignedTimes, features, labels = extractFeatures(data, startTime, sr, featureWindowLength)\n",
    "            labels=[l + identifiers[i] for l in labels]\n",
    "            \n",
    "            if dfs[i] is None:\n",
    "                dfs[i]=pd.DataFrame(features.T,columns=labels,index=alignedTimes)\n",
    "            else:\n",
    "                dfs[i].append(pd.DataFrame(features.T,columns=labels,index=alignedTimes))\n",
    "    \n",
    " \n",
    "    leftWristDF = pd.concat((leftWristDF[:]))\n",
    "    rightWristDF = pd.concat((rightWristDF[:]))\n",
    "    chestDF = pd.concat((chestDF[:]))\n",
    "    \n",
    "    return leftWristDF,rightWristDF,chestDF    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename): \n",
    "    #Extract data\n",
    "    f = pyedflib.EdfReader(filename)\n",
    "    sr = f.getSampleFrequencies()[0]\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[i, :] = f.readSignal(i)    \n",
    "    #Get starting time\n",
    "    startingTime=f.getStartdatetime() #needs to be tested\n",
    "    #startingTime=filename[-19:-4]\n",
    "    #startingTime=pd.to_datetime(startingTime, format='%Y%m%d_%H%M%S', errors='ignore')\n",
    "    #print(startingTime)\n",
    "    return signal_labels, startingTime, sigbufs, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(data, startTime, sr, windowLength=60):\n",
    "    #Filter data between 4 and 8 Hz\n",
    "    #filtData = filter_data(data, sr, 4,8)\n",
    "\n",
    "    #Extract some sort of feature for all windows and corresponding time stamps\n",
    "    numSamples=data.shape[1]\n",
    "    # Getting number and names of features\n",
    "    tremorNames, _ = tremorFeatures(data[:,:windowLength*sr], sr)\n",
    "    bradyNames, _ = bradykinesiaFeatures(data[:,:windowLength*sr], sr)\n",
    "    \n",
    "    numWindows = int(np.floor((numSamples/(windowLength*sr))))\n",
    "    features=np.zeros((len(tremorNames) + len(bradyNames),numWindows))\n",
    "    alignedTimes=[]\n",
    "    for i in range(0,numWindows):\n",
    "        win = i * windowLength * sr\n",
    "        #Average power per channel\n",
    "        #features[:,i]=np.mean(filtData[:,win:win+windowLength*sr]**2,axis=1)\n",
    "        \n",
    "        _, features[:len(tremorNames),i] = tremorFeatures(data[:,win:win+windowLength*sr],sr,windowLength=windowLength)\n",
    "        _, features[len(tremorNames):,i] = bradykinesiaFeatures(data[:,win:win+windowLength*sr],sr,windowLength=windowLength)\n",
    "        # Add the power between 3.6 and 9.4\n",
    "        #Timestamp at beginning of each window\n",
    "        alignedTimes.append(startTime + pd.Timedelta('%d s ' % (i * windowLength)))\n",
    "    return alignedTimes, features, tremorNames + bradyNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tremorFeatures(windowData,sr,windowLength=60):\n",
    "    gyroChannel={'X':3,'Y':4,'Z':5} # gyro is xyz 3-4-5\n",
    "    if windowData.shape[1]!=sr*windowLength:\n",
    "        print(windowData.shape)\n",
    "    freq = np.fft.rfftfreq(windowLength*sr, d=1./sr)\n",
    "    selected=np.logical_and(freq>3.5,freq<7.5)\n",
    "    features=[]\n",
    "    featureNames=[]\n",
    "    for ch in gyroChannel.keys():\n",
    "        spec = np.log(np.sum(np.abs(np.fft.rfft(windowData[gyroChannel[ch],:]))[selected]))\n",
    "        features.append(spec)\n",
    "        featureNames.append('BandPower' + ch)\n",
    "    return featureNames, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bradykinesiaFeatures(windowData,sr,windowLength=60):\n",
    "    features=[]\n",
    "    featureNames=[]\n",
    "    accelerometerChannel={'X':0,'Y':1,'Z':2} # assuming acc xyz 0-1-2 is\n",
    "    \n",
    "    \n",
    "    #windowData = (windowData.T - np.mean(windowData.T,axis=0)).T\n",
    "    #t=time.time()\n",
    "    #windowData = filter_data(windowData,sr,0,3,method='iir',verbose='WARNING')\n",
    "    #print('Filter takes ' + str(time.time()-t))\n",
    "    # lowpass filter signal <3 Hz\n",
    "    \n",
    "    # Features: (Patel et al IEEE 2009)\n",
    "    # rms\n",
    "    # range\n",
    "    # entropy\n",
    "    # normalized cross-correlation value and time point\n",
    "    # dominat frequency and ratio between dominant and rest\n",
    "    freq = np.fft.rfftfreq(windowLength*sr, d=1./sr)\n",
    "    \n",
    "    for ch in accelerometerChannel.keys():\n",
    "        #t = time.time()\n",
    "        #ent = shannon_entropy(windowData[accelerometerChannel[ch],:])\n",
    "        #features.append(ent)\n",
    "        #featureNames.append('Entropy' + ch)\n",
    "        #print('Entropy takes ' + str(time.time()-t))\n",
    "        \n",
    "        #t = time.time()\n",
    "        spec = np.abs(np.fft.rfft(windowData[accelerometerChannel[ch],:]))\n",
    "        domFreq = freq[np.argmax(spec)]\n",
    "        features.append(domFreq)\n",
    "        featureNames.append('DomFreq' + ch)\n",
    "        \n",
    "        \n",
    "        domEnergyRatio = np.max(spec) / np.sum(spec)\n",
    "        features.append(domEnergyRatio)\n",
    "        featureNames.append('DomEnergyRatio' + ch)\n",
    "        \n",
    "        #print('FFT takes ' + str(time.time()-t))\n",
    "        #t=time.time()\n",
    "        rms = np.sqrt(np.mean(windowData[accelerometerChannel[ch],:]**2))\n",
    "        features.append(rms)\n",
    "        featureNames.append('RMS' + ch)\n",
    "        #print('rms takes ' + str(time.time()-t))\n",
    "        \n",
    "        #t = time.time()\n",
    "        ampRange = np.max(windowData[accelerometerChannel[ch],:]) - np.min(windowData[accelerometerChannel[ch],:])\n",
    "        features.append(ampRange)\n",
    "        featureNames.append('AmpRange' + ch)\n",
    "        #print('range takes ' + str(time.time()-t))\n",
    "    \n",
    "    #t=time.time()\n",
    "    cCMax=[]\n",
    "    cCLocs=[]\n",
    "    for i, ch1 in enumerate(accelerometerChannel.keys()):\n",
    "        for j,ch2 in enumerate(list(accelerometerChannel.keys())[i+1:]):\n",
    "            crossCorr = np.correlate(windowData[accelerometerChannel[ch1],:],windowData[accelerometerChannel[ch2],:],'same')\n",
    "            crossCorr = crossCorr/(np.std(windowData[accelerometerChannel[ch1],:]) * np.std(windowData[accelerometerChannel[ch2],:]))\n",
    "            \n",
    "            cCMax.append(np.max(crossCorr))\n",
    "            cCLocs.append(np.argmax(crossCorr))\n",
    "    features.append(np.max(cCMax))\n",
    "    featureNames.append('MaxCC')\n",
    "    features.append(cCLocs[np.argmax(cCMax)])\n",
    "    featureNames.append('MaxCCLoc')\n",
    "    #print('cross-corr takes ' + str(time.time()-t))\n",
    "        #peaks=find_peaks_cwt(windowData[accelerometerChannel[ch],:],np.arange(1,10))\n",
    "        #peaks=[1,2,3]\n",
    "        #features.append(len(peaks))\n",
    "        #featureNames.append('#Movements' + ch)\n",
    "        \n",
    "    #features.append(np.max(windowData[0:3,:]))\n",
    "    #featureNames.append('MaxMovement')\n",
    "    return featureNames, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "accelerometerChannel={'X':0,'Y':1,'Z':2}\n",
    "print(list(accelerometerChannel.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = shannon_entropy([0.3,0.3,0.3])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testL.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "esm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignFeaturesESM(listOfDF,esmFrame,esmColumns,esmWindowLength=15):\n",
    "    \n",
    "    combinedColumns=esmColumns\n",
    "    for featureFrame in listOfDF:\n",
    "        combinedColumns= combinedColumns + featureFrame.keys().tolist()  \n",
    "    esmFeatures=pd.DataFrame(columns=combinedColumns) # Create new empty dataframe with feature and esm columns\n",
    "\n",
    "    hop=np.mean(np.diff(listOfDF[0].index))\n",
    "    for beep in range(esmFrame.shape[0]): #Loop through all the ESM Beeps\n",
    "        beepTime=esmFrame['_datetime'].iloc[beep] # Get the corresponding time\n",
    "        \n",
    "        esmData=np.matlib.repmat(esmFrame.iloc[beep][esmColumns],esmWindowLength,1)\n",
    "        combined=esmData\n",
    "        \n",
    "        subIndex=[beepTime-hop*t for t in range(esmWindowLength)][::-1]\n",
    "        for featureFrame in listOfDF:\n",
    "        \n",
    "        \n",
    "            timediff = np.min(np.abs(featureFrame.index-beepTime)) \n",
    "            # Find corresponding moment for beep time in the sensor data\n",
    "            #print(timediff)\n",
    "            if timediff>timedelta(minutes=esmWindowLength):\n",
    "                # If corresponding time is too far off, remove beep\n",
    "                #print(\"Couldn't find corresponding sensor data\")\n",
    "                continue\n",
    "            pos=np.argmin(np.abs(featureFrame.index-beepTime))\n",
    "            # For the smallest time difference find the position in the sensor data\n",
    "            if pos>esmWindowLength:\n",
    "                featColumns=featureFrame.keys().tolist() #The names of the features                \n",
    "                featData=featureFrame.iloc[pos-esmWindowLength:pos][featColumns].values\n",
    "                # Get corresponding timestamps\n",
    "                \n",
    "                # Repeat ESM data for each data point in the window\n",
    "                combined=np.concatenate((combined,featData),axis=1)\n",
    "                #Combine ESM & feature data\n",
    "        if combined.shape[1]==len(combinedColumns):\n",
    "            esmFeatures=esmFeatures.append(pd.DataFrame(combined,columns=combinedColumns,index=subIndex))\n",
    "                #Append combined data to the dataframe\n",
    "    return esmFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esmFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Align them to the ESM File\n",
    "esmFeatures = alignFeaturesESM([testL,testR,testC],esm[esm['castorID']==110005],esm.keys().tolist(),esmWindowLength=15)\n",
    "\n",
    "#esmFeatures = esmFeatures.dropna() # Drop all lines with missing values, this definitely needs to be refined for real data\n",
    "\n",
    "# Save the dataframe\n",
    "#esmFeatures.to_csv('/Users/jeroenhabets/Desktop/python_code/pilot_testdata/test110001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### END OF DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple analysis\n",
    "\n",
    "# Spearman Correlations\n",
    "r, p = spearmanr(esmFeatures['sanpar_tremor'],esmFeatures['BandPowerXC']+esmFeatures['BandPowerYC']+esmFeatures['BandPowerZC'])\n",
    "print('Spearman correlation of r = %f with a p-value of %f' % (r, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use Machine Learning to predict some variable from the esm\n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "# Fitting the linear regression to the data\n",
    "lr.fit(esmFeatures[['BandPowerXR','BandPowerYL', '#MovementsXL']].values,esmFeatures['stress'])\n",
    "# Looking at model parameters\n",
    "# Regression weights\n",
    "print('Weights are %f, %f, %f ' % (lr.coef_[0], lr.coef_[1], lr.coef_[2]))\n",
    "# Intercept\n",
    "print('Intercept is %f' % lr.intercept_)\n",
    "\n",
    "# Predict target variable based on input data (should be unseen data)\n",
    "prediction = lr.predict(esmFeatures[['BandPowerXR','BandPowerYL', '#MovementsXL']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Data visualization\n",
    "# Bar plot\n",
    "fig,ax = plt.subplots()\n",
    "ax.bar(range(3), lr.coef_,color='r',width=0.4)\n",
    "ax.bar(np.arange(3)+0.4, lr.coef_+0.01, color='b',width=0.4)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Weight')\n",
    "plt.title('Linear Regression Weights')\n",
    "plt.xticks(range(3),['BandPowerXR','BandPowerYL', '#MovementsXL'])\n",
    "plt.yticks(np.arange(0,0.1,0.02))\n",
    "plt.savefig('weights.png',dpi=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "feature1='BandPowerXR'\n",
    "feature2='BandPowerYL'\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "s1 = ax.scatter(esmFeatures[feature1], esmFeatures[feature2], c=esmFeatures['cheerful'])\n",
    "plt.xlabel(feature1)\n",
    "plt.ylabel(feature2)\n",
    "fig.colorbar(s1,label='Cheerful')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "plt.hist(esmFeatures['#MovementsXR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "def pca(data):\n",
    "    # Calculate Covariance Matrix\n",
    "    cov=np.cov(data.T)\n",
    "    # Calculate Eigenvalues and Eigenvectors\n",
    "    w, v = np.linalg.eig(cov)\n",
    "    # Sort them\n",
    "    s= np.argsort(w)[::-1]\n",
    "    return v[:,s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could also be done in only sensor/esm spaces\n",
    "esmEigenVectors = pca(esmFeatures.values.astype(float))\n",
    "transformedFeatureSpace =np.dot(esmEigenVectors[:,:2].T,esmFeatures.values.astype(float).T).T\n",
    "s1 = plt.scatter(transformedFeatureSpace[:,0],transformedFeatureSpace[:,1],c=esmFeatures['cheerful'])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(s1, label = 'Cheerful')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is very easy to use a more powerful Machine Learning algorithm\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "est = GradientBoostingRegressor()\n",
    "# Fitting the regression model to our data\n",
    "est.fit(esmFeatures[['BandPowerXR','BandPowerYL', '#MovementsXL']].values,esmFeatures['stress'])\n",
    "\n",
    "# Interpreting the model\n",
    "print(est.feature_importances_)\n",
    "\n",
    "# Predict target variable based on input data (should be unseen data)\n",
    "prediction = est.predict(esmFeatures[['BandPowerXR','BandPowerYL', '#MovementsXL']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "r,p=spearmanr(alignedFeatures['AccX'].values.tolist(),alignedFeatures['cheerful'].values.tolist(),nan_policy='omit')\n",
    "print(r,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Exploring the sensor data\n",
    "\n",
    "signal_labels, timeStamps, data, sr = readData(leftWristFile)\n",
    "\n",
    "#filtData = filter_data(data, sr, 4,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extract some sort of feature for all windows and corresponding time stamps\n",
    "# Peak detection\n",
    "\n",
    "\n",
    "channel=3\n",
    "numSamples=data.shape[1]\n",
    "windowLength=60\n",
    "\n",
    "win=0\n",
    "windowData = data[:,win:win+featureWindowLength*sr]\n",
    "\n",
    "peaks=find_peaks_cwt(windowData[channel,:],np.arange(40,50))\n",
    "\n",
    "#Maximum for bradykinesia recognition\n",
    "mMovement = np.max(windowData[3:6,:])\n",
    "numberOfPeaks = len(peaks)\n",
    "averageDuration = np.mean(np.diff(peaks))/sr\n",
    "\n",
    "\n",
    "plt.plot(windowData[channel,:])\n",
    "plt.scatter(peaks,windowData[channel,peaks],c='r')\n",
    "plt.show()\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiments with Orientation estimation\n",
    "signal_labels, timeStamps, sigbufs, sr = readData(leftWristFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform Gyro data into orientation estimation\n",
    "from madgwickahrs import MadgwickAHRS\n",
    "mw = MadgwickAHRS(sampleperiod=1/sr)\n",
    "euler = np.zeros((3,sigbufs.shape[1]))\n",
    "for sample in range(sigbufs.shape[1]):\n",
    "    mw.update_imu(sigbufs[6:,sample],sigbufs[3:6,sample])\n",
    "    euler[:,sample] = mw.quaternion.to_euler123()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(euler,aspect='auto')\n",
    "plt.yticks([0,1,2],['Roll', 'Pitch', 'Yaw'])\n",
    "plt.xlabel('Time in samples')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
